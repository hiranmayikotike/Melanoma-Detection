{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4faa5501",
   "metadata": {},
   "source": [
    "# Detecting Melanoma with a Convolutional Neural Network\n",
    "To design an algorithm that can visually diagnose melanoma, the deadliest form of skin cancer. In particular, the algorithm will distinguish this malignant skin tumor from two types of benign lesions (nevis and seborrheic keratoses)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875ff11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "![](https://d17h27t6h515a5.cloudfront.net/topher/2017/November/5a18789d_skin-disease-classes/skin-disease-classes.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1fcaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # Plotting library\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "from keras.utils import np_utils\n",
    "from sklearn.datasets import load_files   \n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cb15c4",
   "metadata": {},
   "source": [
    "There are a lot more samples of nevus compared to the other two. This might cause the network to be biased. It will try to maximize the error function, and by classifying everything as nevus it will accomplish that.\n",
    "\n",
    "For this problem we will need to be careful with the accuracy metric. I will try to balance the data in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168e581a",
   "metadata": {},
   "source": [
    "# 1. Load the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d4fd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_path = '../input/skin-lesion-analysis-towards-melanoma-detection/train/train'\n",
    "data_valid_path = '../input/skin-lesion-analysis-towards-melanoma-detection/valid/valid'\n",
    "data_test_path = '../input/skin-lesion-analysis-towards-melanoma-detection/test/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119087e2",
   "metadata": {},
   "source": [
    "# define function to load train, test, and validation datasets\n",
    "def load_data_raw (path):\n",
    "    data = load_files(path)\n",
    "    files = np.array(data['filenames'])\n",
    "    targets = np_utils.to_categorical(np.array(data['target']), 3)\n",
    "    \n",
    "    return files, targets\n",
    "\n",
    "train_filenames, train_targets = load_data_raw(data_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9be0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_trimmed = [filename.split('/')[-2] for filename in train_filenames]\n",
    "classes_count = Counter(filenames_trimmed)\n",
    "\n",
    "# Plot the classes\n",
    "plt.bar(classes_count.keys(), classes_count.values(), color=['blue', 'orange', 'green'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdb4b9d",
   "metadata": {},
   "source": [
    "**Upsampling function for imbalanced data**\n",
    "\n",
    "Using scikit learn's resample function I will create new samples of the under-represented data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d704cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_n_samples(filenames):\n",
    "    filenames_trimmed = [filename.split('/')[-2] for filename in filenames]\n",
    "    classes_count = Counter(filenames_trimmed)\n",
    "\n",
    "    # Plot the classes\n",
    "    plt.bar(classes_count.keys(), classes_count.values(), color=['blue', 'orange', 'green'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72991d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample, shuffle\n",
    "\n",
    "# Choose one of the 3 for the feature_name\n",
    "feature_names = {0: 'melanoma', 1: 'nevus', 2: 'seborrheic_keratosis'}\n",
    "\n",
    "def upsample(filenames, targets, feature_name, n_samples = 1372):\n",
    "    upsample_idx = []\n",
    "    \n",
    "\n",
    "    # Find all the indices for nevus\n",
    "    for i, path in enumerate(filenames):\n",
    "        # If feature matches, save the index\n",
    "        if feature_name in path.split('/'):\n",
    "            upsample_idx.append(i)\n",
    "    \n",
    "    # Remove selected features from filenames to add the upsampled after\n",
    "    new_filenames = [filename for i, filename in enumerate(filenames) if i not in upsample_idx]\n",
    "    new_targets = [target for i, target in enumerate(targets) if i not in upsample_idx]\n",
    "\n",
    "    # Upsample\n",
    "    resampled_x, resampled_y = resample(filenames[upsample_idx], targets[upsample_idx], n_samples=n_samples, random_state=0)\n",
    "\n",
    "    # Add the upsampled features to new_filenames and new_targets\n",
    "    new_filenames += list(resampled_x)\n",
    "    new_targets += list(resampled_y) \n",
    "    \n",
    "    return np.array(new_filenames), np.array(new_targets)\n",
    "    \n",
    "# We upsample twice: once for each feature we want upsampled\n",
    "upsample_train_x, upsample_train_y = upsample(train_filenames, train_targets, feature_names[0])\n",
    "upsample_train_x, upsample_train_y = upsample(upsample_train_x, upsample_train_y, feature_names[2])\n",
    "\n",
    "plot_n_samples(upsample_train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5957b17b",
   "metadata": {},
   "source": [
    "**Downsampling function for imbalanced data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f513717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Use only if not using the up-sampling function\\ndef downsample(filenames, targets, n_samples = 370):\\n    nevus_idx = []\\n    \\n    # Find all the indices for nevus\\n    for i, path in enumerate(filenames):\\n        # If nevus, save the index\\n        if 'nevus' in path.split('/'):\\n            nevus_idx.append(i)\\n    \\n    nevus_idx = np.sort(shuffle(nevus_idx)[n_samples:]) # shuffle indices\\n\\n    # Downsample\\n    new_filenames = [filename for i, filename in enumerate(filenames) if i not in nevus_idx]\\n    new_targets = [target for i, target in enumerate(targets) if i not in nevus_idx]\\n    \\n    \\n    return new_filenames, new_targets\\n            \\ndownsample_train_x, downsample_train_y = downsample(train_filenames, train_targets)\\n\\nplot_n_samples(downsample_train_x)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Use only if not using the up-sampling function\n",
    "def downsample(filenames, targets, n_samples = 370):\n",
    "    nevus_idx = []\n",
    "    \n",
    "    # Find all the indices for nevus\n",
    "    for i, path in enumerate(filenames):\n",
    "        # If nevus, save the index\n",
    "        if 'nevus' in path.split('/'):\n",
    "            nevus_idx.append(i)\n",
    "    \n",
    "    nevus_idx = np.sort(shuffle(nevus_idx)[n_samples:]) # shuffle indices\n",
    "\n",
    "    # Downsample\n",
    "    new_filenames = [filename for i, filename in enumerate(filenames) if i not in nevus_idx]\n",
    "    new_targets = [target for i, target in enumerate(targets) if i not in nevus_idx]\n",
    "    \n",
    "    \n",
    "    return new_filenames, new_targets\n",
    "            \n",
    "downsample_train_x, downsample_train_y = downsample(train_filenames, train_targets)\n",
    "\n",
    "plot_n_samples(downsample_train_x)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31ec7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image   \n",
    "\n",
    "# Convert the image paths to tensors Manually\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224,224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "\n",
    "train_filenames = paths_to_tensor(upsample_train_x)\n",
    "train_targets = upsample_train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da636d86",
   "metadata": {},
   "source": [
    "**Load the mdata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c445aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=60\n",
    "\n",
    "# Transforms\n",
    "datagen_train = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally \n",
    "    height_shift_range=0.1,  # randomly shift images vertically\n",
    "    horizontal_flip=True)\n",
    "\n",
    "datagen_valid = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally\n",
    "    height_shift_range=0.1,  # randomly shift images vertically\n",
    "    horizontal_flip=True)\n",
    "\n",
    "datagen_test = ImageDataGenerator(\n",
    "    rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e0d9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generators\n",
    "'''\n",
    "train_generator = datagen_train.flow_from_directory(\n",
    "        data_train_path,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "'''\n",
    "\n",
    "train_generator = datagen_train.flow(train_filenames, train_targets, batch_size=batch_size)\n",
    "\n",
    "valid_generator = datagen_valid.flow_from_directory(\n",
    "        data_valid_path,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "test_generator = datagen_test.flow_from_directory(\n",
    "        data_test_path,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=1,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cc50d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(train_filenames)\n",
    "num_valid = len(valid_generator.filenames)\n",
    "num_test = len(test_generator.filenames)\n",
    "\n",
    "print(num_train, num_valid, num_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9372369d",
   "metadata": {},
   "source": [
    "Get the class indices\n",
    "\n",
    "To get the label we find the index of the 1 in the one hot encoded vector which should match the index in a dictionary. Eg:\n",
    "* label = `[1,0,0]` ---> class_index = `0`\n",
    "* label = `[0,1,0]` ---> class_index = `1`\n",
    "* label = `[0,0,1]` ---> class_index = `2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9eb87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class name to the index\n",
    "#class_2_indices = train_generator.class_indices\n",
    "class_2_indices = {'melanoma': 0, 'nevus': 1, 'seborrheic_keratoses': 2}\n",
    "print(\"Class to index:\", class_2_indices)\n",
    "\n",
    "# Reverse dict with the class index to the class name\n",
    "indices_2_class = {v: k for k, v in class_2_indices.items()}\n",
    "print(\"Index to class:\", indices_2_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477ac36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets have a look at some of our images\n",
    "images, labels = train_generator.next()\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "fig.subplots_adjust(wspace=0.2, hspace=0.4)\n",
    "\n",
    "# Lets show the first 32 images of a batch\n",
    "for i, img in enumerate(images[:32]):\n",
    "    ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(img)\n",
    "    image_idx = np.argmax(labels[i])\n",
    "    ax.set(title=indices_2_class[image_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990c1dd0",
   "metadata": {},
   "source": [
    "# 2. Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2336a41d",
   "metadata": {},
   "source": [
    "**Log**\n",
    "\n",
    "```\n",
    "> Used VGG19 pre-trained (frozen layers) with 2 fully connected layers and got no improvement over 50%.\n",
    "\n",
    "> Used InceptionV3 pre-trained (frozen layers) with 2 fully connected layers and got no improvement over 50%.\n",
    "\n",
    "> Used InceptionV3 pre-trained, (de-frosted layers lol) and with 3 fully connected layers and got no improvement over 50%.\n",
    "\n",
    "> Used ResNet50 ... same.\n",
    "\n",
    "> Changed Flatten layer to GlobalAveragePooling and it seems to perform better.\n",
    "\n",
    "> Added class_weights to help balance the classes.\n",
    "\n",
    "> Downsampled the data with the most occurrences (nevus). I am not getting everything predicted as nevus anymore, but I still get low ROC AUC scores (even below 0.5, which would actually kill people!!!).\n",
    "\n",
    "> ResNet50 with 1 hidden layer and 0.95 Dropout. Accuracy has improved slightly to ~ 0.65. RocAuc scores still bad.\n",
    "\n",
    "> Keras .flow's property shuffle was set to True by default. Changed it as it was the cause for getting such horrible ROC AUC scores. Now the Auc Scores look a lot better.\n",
    "\n",
    "> Tried oversampling by repeating some of the downsampled images. Results improved. Better results than performing undersampling.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbea6f8f",
   "metadata": {},
   "source": [
    "**Define the model architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dea0552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.applications import ResNet50\n",
    "from keras.models import Model\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# x = MaxAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='elu')(x)\n",
    "x = Dropout(0.95)(x)\n",
    "# and a logistic layer\n",
    "predictions = Dense(3, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2432bb1b",
   "metadata": {},
   "source": [
    "**Trying out a custom made model for debugging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2448c114",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model = Sequential()\n",
    "\n",
    "### TODO: Define your architecture.\n",
    "model.add(Conv2D(filters=16, kernel_size=2, padding='same',\n",
    "                  input_shape=(224,224,3), kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Conv2D(32, (3,3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Conv2D(128, (3,3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(256, (3,3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "          \n",
    "model.summary()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55f5682",
   "metadata": {},
   "source": [
    "**Compile the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa7c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cf5f74",
   "metadata": {},
   "source": [
    "# 3.Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4363138",
   "metadata": {},
   "source": [
    "**Assign weights to imbalanced classes**\n",
    "\n",
    "The dataset shows an imbalance. By assigning bigger weights to the misrepresented classes in the dataset we will help to correct this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fafce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Convert one hot encoded labels to ints\n",
    "train_targets_classes = [np.argmax(label) for label in train_targets]\n",
    "\n",
    "# Compute the weights\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                  np.unique(train_targets_classes),\n",
    "                                                  train_targets_classes)\n",
    "\n",
    "class_weights_dict = dict(enumerate(class_weights))\n",
    "print(class_weights_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed00218a",
   "metadata": {},
   "source": [
    "**Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c39b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='aug_model.weights.best.hdf5', verbose=1, \n",
    "                               save_best_only=True)\n",
    "\n",
    "scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=5, min_lr=1e-8, verbose=1)\n",
    "\n",
    "early_stopper = EarlyStopping(monitor='val_loss', patience=10,\n",
    "                              verbose=0, restore_best_weights=True)\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                    class_weight= class_weights_dict,\n",
    "                    steps_per_epoch=num_train//batch_size,\n",
    "                    epochs=40,\n",
    "                    verbose=0,\n",
    "                    callbacks=[checkpointer, scheduler, TQDMNotebookCallback(), early_stopper],\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=num_valid//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c17d1d",
   "metadata": {},
   "source": [
    "# 4. Test model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca58975",
   "metadata": {},
   "source": [
    "**Load the model with the best Validation Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0248ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights that yielded the best validation accuracy\n",
    "model.load_weights('aug_model.weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a1fc16",
   "metadata": {},
   "source": [
    "**Predictions for the test data**\n",
    "\n",
    "* `task_1`: the model's predicted probability that the image depicts **melanoma**\n",
    "* `task_2`: the model's predicted probability that the image depicts **seborrheic keratosis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85b9caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(test_generator, steps=num_test)\n",
    "\n",
    "task_1 = pd.DataFrame(data=[desease[0] for desease in predictions])\n",
    "task_2 = pd.DataFrame(data=[desease[2] for desease in predictions])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0988b129",
   "metadata": {},
   "source": [
    "**RocAuc Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63dc977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "ground_truth = pd.read_csv(\"../input/udacitydermatologistai/repository/udacity-dermatologist-ai-2ec0ca9/ground_truth.csv\")\n",
    "labels = np_utils.to_categorical(np.array(test_generator.classes), 3)\n",
    "\n",
    "roc_auc_all = roc_auc_score(labels, predictions)\n",
    "roc_auc_task_1 = roc_auc_score(ground_truth['task_1'], task_1)\n",
    "roc_auc_task_2 = roc_auc_score(ground_truth['task_2'], task_2)\n",
    "\n",
    "print('Roc auc score for all data is: {}'.format(roc_auc_all))\n",
    "print('Roc auc score for task 1 is: {}'.format(roc_auc_task_1))\n",
    "print('Roc auc score for task 2 is: {}'.format(roc_auc_task_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c2e813",
   "metadata": {},
   "source": [
    "**Visualizing some of our predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eb3a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames, test_targets = load_data_raw(data_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fe1b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(img_file, img_target):\n",
    "\n",
    "    img = image.load_img(img_file, target_size=(224,224))\n",
    "    img = image.img_to_array(img)/255\n",
    "    img_expand = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    # Make a prediction\n",
    "    prediction = model.predict(img_expand, steps=1)\n",
    "    image_idx = np.argmax(prediction[0])\n",
    "    prediction_string = indices_2_class[image_idx]\n",
    "    \n",
    "    # Get the real label's name\n",
    "    label_idx = np.argmax(img_target)\n",
    "    real_label = indices_2_class[label_idx]\n",
    "    \n",
    "    # Plot predictions\n",
    "    title = \"Prediction: {}\\nReal: {}\".format(prediction_string, real_label)\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    plt.title(title)\n",
    "    \n",
    "    pred_df = pd.DataFrame({'Cancer type':['melanoma', 'nevus', 'seborrheic keratosis'], 'val':prediction[0]})\n",
    "    ax = pred_df.plot.barh(x='Cancer type', y='val', title=\"Predictions\", grid=True)\n",
    "    \n",
    "random_index = np.random.randint(0, len(test_generator.filenames))\n",
    "plot_prediction(test_filenames[random_index], test_targets[random_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae087a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plts, (ax1, ax2) = plt.subplots(1,2, figsize=(20,5))\n",
    "\n",
    "# summarize history for accuracy\n",
    "ax1.plot(history.history['acc'])\n",
    "ax1.plot(history.history['val_acc'])\n",
    "ax1.set_title('model accuracy')\n",
    "ax1.set(xlabel='epoch', ylabel='accuracy')\n",
    "ax1.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "ax2.plot(history.history['loss'])\n",
    "ax2.plot(history.history['val_loss'])\n",
    "ax2.set_title('model loss')\n",
    "ax2.set(xlabel='epoch', ylabel='loss')\n",
    "ax2.legend(['train', 'val'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72563100",
   "metadata": {},
   "source": [
    "# 5. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f6a5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission\n",
    "submission = pd.read_csv(\"../input/udacitydermatologistai/repository/udacity-dermatologist-ai-2ec0ca9/sample_predictions.csv\")\n",
    "submission['task_1'] = task_1\n",
    "submission['task_2'] = task_2\n",
    "submission.to_csv(\"submission_dermatologist.csv\", index=False)\n",
    "display(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f214d8d",
   "metadata": {},
   "source": [
    "# 6. Conclussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f7a102",
   "metadata": {},
   "source": [
    "Due to the nature of the problem, it is very important that we make no mistake when identifying a patient as _not sick_. We prefer to send someone who is not sick for more tests, rather than someone who is sick home. This is what we know as recall, and we want a value for recall as close to 1 as possible. To improve recall what we can do is set a lower threshold to idenfify someone as sick or not sick, therefore only the pateients with a really low probability of melanoma will be let go, any others with a higher predicted chance will be held for more tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39877ca3",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3386049",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Confusion matrix for all classes\n",
    "y_true = test_generator.classes\n",
    "y_pred = [np.argmax(x) for x in predictions]\n",
    "\n",
    "labels = [\"melanoma\", \"nevus\", \"keratoses\"]\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] # Normalize confusion matrix\n",
    "ax = sns.heatmap(cm, annot=True)\n",
    "ax.xaxis.set_ticklabels(labels)\n",
    "ax.yaxis.set_ticklabels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2f55e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(pred_target_y, filenames):\n",
    "    melanoma_idx = []\n",
    "      \n",
    "    # Find all the indices for nevus\n",
    "    for i, path in enumerate(filenames):\n",
    "        # If feature matches, save the index\n",
    "        if 'melanoma' in path.split('/'):\n",
    "            melanoma_idx.append(i)\n",
    "            \n",
    "    bening_preds = [pred for i, pred in enumerate(pred_target_y) if i not in melanoma_idx]\n",
    "    malignant_preds = [pred for i, pred in enumerate(pred_target_y) if i in melanoma_idx]\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1,figsize=(15,6))\n",
    "    \n",
    "    ax.set_title('Malignant vs. Bening')\n",
    "    sns.distplot(bening_preds, hist=True, kde=True, label=\"Benign\", bins=35)\n",
    "    sns.distplot(malignant_preds, hist=True, kde=True, label=\"Malignant\", bins=35, axlabel=\"Probability Malignant\")\n",
    "    ax.legend()\n",
    "    ax.xaxis.set_ticks(np.arange(0, 1.1, 0.1))\n",
    "\n",
    "plot_distribution(task_1.values, test_generator.filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cfdf6a",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "\n",
    "We can see the a little the separation between malignant and bening lesions. This plot could be used to find the best threshold that maximizes the amount of people that have malignant lesions.\n",
    "* The model predicts that about 50% of the malignant lesions are bening (Really close to 0%)\n",
    "* The model predicts correctly 50% of the malignant lesions as malignant (as we can see in the confusion matrix)\n",
    "* In the event that we had to choose a threshold (this is dangerous because a lot of our malignant lesions are very near the 0), we could say that a \"good\" threshold is around 0.05, where it identifies a lot of malignant lesions (more than 50% at least) and leaves back most benign lesions (more than 90%)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
